<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>learning_model &mdash; repoclass 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=f2a433a1"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            repoclass
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">Modules</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">repoclass</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Module code</a></li>
      <li class="breadcrumb-item active">learning_model</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for learning_model</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This module contains the definition models for the neural network.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">ast</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span>
<span class="kn">from</span> <span class="nn">nlp_embedding</span> <span class="kn">import</span> <span class="n">NlpEmbedding</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;TFM&quot;</span><span class="p">)</span>
<span class="n">printer</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;printer&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="StopTraining">
<a class="viewcode-back" href="../learning_model.html#learning_model.StopTraining">[docs]</a>
<span class="k">class</span> <span class="nc">StopTraining</span><span class="p">(</span><span class="ne">Exception</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Custom exception to stop training the model.</span>
<span class="sd">    &quot;&quot;&quot;</span></div>



<div class="viewcode-block" id="CategoricNeuralNetwork">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork">[docs]</a>
<span class="k">class</span> <span class="nc">CategoricNeuralNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A neural network model for categoric data.</span>

<span class="sd">    The model can be trained using a dataset containing input and output data. The model</span>
<span class="sd">    can be trained to predict the output data based on the input data.</span>

<span class="sd">    The model is designed to work with categoric data, such as the names of functions</span>
<span class="sd">    and their test cases. It can be used to predict categories based on the input data.</span>

<span class="sd">    The model can use embeddings for the input and output data. The input data can be</span>
<span class="sd">    embedded using a pretrained NLP model, and the output data can be embedded using</span>
<span class="sd">    the same model. Embedding either is applied independtly of each other.</span>

<span class="sd">    The model can be trained to update the embeddings of the NLP model. This can be</span>
<span class="sd">    useful when the model is used in a domain-specific context where the pretrained</span>
<span class="sd">    embeddings are not sufficient.</span>

<span class="sd">    The model can be configured to use a different number of hidden layers and neurons</span>
<span class="sd">    in the hidden layers. The number of hidden layers and neurons can be specified when</span>
<span class="sd">    creating the model.</span>

<span class="sd">    Methods:</span>
<span class="sd">        forward: The forward pass of the model.</span>
<span class="sd">        train_loop: The training loop of the model.</span>
<span class="sd">        test_loop: The testing loop of the model.</span>
<span class="sd">        evaluate: Evaluates the model on a test instance (direct).</span>
<span class="sd">        execute: Executes the model on a test instance (wrapper of evaluate).</span>
<span class="sd">        build_neural_network: Builds the neural network.</span>
<span class="sd">        add_layer: Adds a layer to the model.</span>
<span class="sd">        _process_batch_to_embedding: Preprocesses the batch to embeddings.</span>
<span class="sd">        _process_batch_to_one_hot: Preprocesses the batch to one-hot vectors.</span>
<span class="sd">        _get_batch_loss: Computes the loss for a batch of data.</span>
<span class="sd">        _get_multi_one_hot: Preprocesses the field value to a multi-hot vector.</span>
<span class="sd">        _configure_input: Initializes the input size.</span>
<span class="sd">        _configure_output: Initializes the output size.</span>
<span class="sd">        _initialize_weights: Initializes the weights and biases of the model.</span>
<span class="sd">        _get_performance: Calculates the performance of the model.</span>
<span class="sd">        _compute_total_metrics: Computes the total metrics of the model.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        category_mappings: A dictionary containing the mappings of the categories.</span>
<span class="sd">        max_hidden_neurons: The maximum number of hidden neurons in the hidden layers.</span>
<span class="sd">        hidden_layers: The number of hidden layers in the model.</span>
<span class="sd">        use_input_embedding: Whether to use input embeddings or not.</span>
<span class="sd">        use_output_embedding: Whether to use output embeddings or not.</span>
<span class="sd">        train_nlp_embedding: Whether to train the NLP embedding model or not.</span>
<span class="sd">        nlp_model_name: The name of the NLP model to use for embeddings.</span>
<span class="sd">        device: The device to use for the model.</span>
<span class="sd">        _use_input_embedding: Whether to use input embeddings or not.</span>
<span class="sd">        _use_output_embedding: Whether to use output embeddings or not.</span>
<span class="sd">        _nlp_model_name: The name of the NLP model to use for embeddings.</span>
<span class="sd">        _device: The device to use for the model.</span>
<span class="sd">        _nlp_embedding_model: The NLP embedding model to use for embeddings.</span>
<span class="sd">        _output_category_embeddings_nlp: The output category embeddings for the NLP model.</span>
<span class="sd">        _similarity_threshold: The similarity threshold to use for the model (Cosine Embeddings).</span>
<span class="sd">        _train_nlp_embedding: Whether to train the NLP embedding model or not.</span>
<span class="sd">        _input_size: The size of the input data.</span>
<span class="sd">        _output_size: The size of the output data.</span>
<span class="sd">        linear_relu_stack: The neural network model.</span>
<span class="sd">        softmax: The softmax function.</span>
<span class="sd">        cos: The cosine similarity function.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="o">/</span><span class="p">,</span>
            <span class="n">category_mappings</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span>
            <span class="n">max_hidden_neurons</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">13</span><span class="p">,</span>
            <span class="n">hidden_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
            <span class="n">use_input_embedding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
            <span class="n">use_output_embedding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">train_nlp_embedding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">nlp_model_name</span><span class="o">=</span><span class="s1">&#39;distilbert-base-uncased&#39;</span><span class="p">,</span>
            <span class="n">similarity_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span>
            <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Save all input parameters in a dictionary for easy access</span>
        <span class="c1"># later when we save it to a file.</span>
        <span class="c1"># This is only to create the new instance when loading the model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;category_mappings&quot;</span><span class="p">:</span> <span class="n">category_mappings</span><span class="p">,</span>
            <span class="s2">&quot;max_hidden_neurons&quot;</span><span class="p">:</span> <span class="n">max_hidden_neurons</span><span class="p">,</span>
            <span class="s2">&quot;hidden_layers&quot;</span><span class="p">:</span> <span class="n">hidden_layers</span><span class="p">,</span>
            <span class="s2">&quot;use_input_embedding&quot;</span><span class="p">:</span> <span class="n">use_input_embedding</span><span class="p">,</span>
            <span class="s2">&quot;use_output_embedding&quot;</span><span class="p">:</span> <span class="n">use_output_embedding</span><span class="p">,</span>
            <span class="s2">&quot;train_nlp_embedding&quot;</span><span class="p">:</span> <span class="n">train_nlp_embedding</span><span class="p">,</span>
            <span class="s2">&quot;nlp_model_name&quot;</span><span class="p">:</span> <span class="n">nlp_model_name</span><span class="p">,</span>
            <span class="s2">&quot;similarity_threshold&quot;</span><span class="p">:</span> <span class="n">similarity_threshold</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">assess_device</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_input_embedding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">use_input_embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_output_embedding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">use_output_embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_model_name</span> <span class="o">=</span> <span class="n">nlp_model_name</span>
        <span class="c1"># Initialize the NLP embedding model if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_input_embedding</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_output_embedding</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Using no embeddings.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_embedding_model</span><span class="p">:</span> <span class="n">NlpEmbedding</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_embedding_model</span><span class="p">:</span> <span class="n">NlpEmbedding</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="n">NlpEmbedding</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_nlp_model_name</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_embedding_model</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
            <span class="c1"># # We will also need an RNN layer to process the embeddings</span>
            <span class="c1"># logger.info(&quot;Because embeddings are being used, an RNN layer will be added to the model.&quot;)</span>
            <span class="c1"># self.rnn = nn.RNN(</span>
            <span class="c1">#     input_size=self._nlp_embedding_model.model.config.hidden_size,</span>
            <span class="c1">#     hidden_size=self._nlp_embedding_model.model.config.hidden_size,</span>
            <span class="c1">#     num_layers=1,</span>
            <span class="c1">#     batch_first=True,</span>
            <span class="c1">#     nonlinearity=&#39;relu&#39;,</span>
            <span class="c1">#     dropout=0.3,</span>
            <span class="c1">#     )</span>
        <span class="c1"># make a dict of each element of dataset.input_columns and their corresponding index in the list</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="n">category_mappings</span>
        <span class="c1"># &quot;Private&quot; variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_category_embeddings_nlp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_similarity_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">similarity_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_nlp_embedding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">train_nlp_embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Initialize the input size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_configure_input</span><span class="p">()</span>
        <span class="c1"># Initialize the output size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_configure_output</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_nlp_embedding</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_embedding_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Training the NLP embedding model can be very slow and resource-intensive.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;It is recommended to not train pretrained models further.&quot;</span>
                <span class="s2">&quot;It can also be very unstable and might not converge.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_embedding_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_nlp_embedding</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_embedding_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_embedding_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">printer</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Input size: </span><span class="si">%s</span><span class="s2">, Mapping to Output size: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_size</span><span class="p">)</span>

        <span class="c1"># Initialize the hidden layers</span>
        <span class="c1"># Define the neural network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
        <span class="n">printer</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Estimating the number of neurons needed in the hidden layers.&quot;</span><span class="p">)</span>
        <span class="n">neurons</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># dummy counter variable</span>
        <span class="n">i</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="n">neurons</span> <span class="o">&lt;</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_size</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_size</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">neurons</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="n">i</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># limit to avoid memory issues</span>
        <span class="n">neurons</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">neurons</span><span class="p">,</span> <span class="n">max_hidden_neurons</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build_neural_network</span><span class="p">(</span><span class="n">neurons</span><span class="p">,</span> <span class="n">number_layers</span><span class="o">=</span><span class="n">hidden_layers</span><span class="p">)</span>

        <span class="c1"># Proceed to initialize the weights and biases</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_weights</span><span class="p">()</span>

        <span class="c1"># Define the softmax and cosine similarity functions for easy access</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cos</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">CosineSimilarity</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CosineSimilarity</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Print the parameters that will be trained</span>
        <span class="n">training_message</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;The following parameters will be trained:&quot;</span><span class="p">]</span>
        <span class="n">not_training_message</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;The following parameters will not be trained:&quot;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="n">training_message</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">not_training_message</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> will not be part of the learning layer&quot;</span><span class="p">)</span>
        <span class="n">printer</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">training_message</span><span class="p">))</span>
        <span class="n">printer</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">not_training_message</span><span class="p">))</span>

<div class="viewcode-block" id="CategoricNeuralNetwork.build_neural_network">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork.build_neural_network">[docs]</a>
    <span class="k">def</span> <span class="nf">build_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neurons</span><span class="p">,</span> <span class="n">number_layers</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Builds the neural network.</span>

<span class="sd">        The neural network is built with a number of hidden layers</span>
<span class="sd">        and a number of neurons per layer that decreases gradually</span>
<span class="sd">        from the input size to the output size.</span>

<span class="sd">        Args:</span>
<span class="sd">            neurons (int): The number of neurons in the hidden layers.</span>
<span class="sd">            number_layers (int): The number of hidden layers.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">neurons_per_layer</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="c1"># decrease the number of neurons per layer gradually into the output size</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">number_layers</span><span class="p">):</span>
            <span class="n">neurons_per_layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">neurons</span> <span class="o">-</span> <span class="p">(</span><span class="n">neurons</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">i</span> <span class="o">/</span> <span class="n">number_layers</span><span class="p">))</span>
        <span class="n">neurons_per_layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_layer</span><span class="p">(</span><span class="s2">&quot;Layer0&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_size</span><span class="p">,</span> <span class="n">neurons_per_layer</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_layers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_layer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Layer</span><span class="si">{</span><span class="mi">1</span><span class="o">+</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">neurons_per_layer</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">neurons_per_layer</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># add the output layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_layer</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Layer</span><span class="si">{</span><span class="mi">1</span><span class="o">+</span><span class="n">number_layers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span>
            <span class="n">neurons_per_layer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_size</span><span class="p">,</span>
            <span class="n">add_activation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">add_drop</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">add_normalization</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using a model with the following setup:</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span><span class="p">))</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork.add_layer">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork.add_layer">[docs]</a>
    <span class="k">def</span> <span class="nf">add_layer</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
            <span class="n">layer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
            <span class="n">neurons_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">neurons_out</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">add_normalization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
            <span class="n">add_activation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
            <span class="n">add_drop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds a layer to the model.</span>

<span class="sd">        The layer can be a linear layer, and can have normalization,</span>
<span class="sd">        activation, and dropout layers after it. The layer is added</span>
<span class="sd">        to the linear_relu_stack attribute of the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            layer (nn.Module): The layer to be added.</span>
<span class="sd">            neurons (int): The number of neurons in the layer.</span>
<span class="sd">            add_activation (bool): Whether to add an activation function after the layer.</span>
<span class="sd">            add_normalization (bool): Whether to add a normalization layer after the layer.</span>
<span class="sd">            add_drop (bool): Whether to add a dropout layer after the layer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">layer</span><span class="p">(</span><span class="n">neurons_in</span><span class="p">,</span> <span class="n">neurons_out</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">add_normalization</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">name</span><span class="o">+</span><span class="s2">&quot;_1&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">neurons_out</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">add_activation</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">name</span><span class="o">+</span><span class="s2">&quot;_2&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">add_drop</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">name</span><span class="o">+</span><span class="s2">&quot;_3&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork._configure_input">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork._configure_input">[docs]</a>
    <span class="k">def</span> <span class="nf">_configure_input</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the input size.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_input_embedding</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_embedding_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_categories</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">[</span><span class="n">col</span><span class="p">])</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_categories</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork._configure_output">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork._configure_output">[docs]</a>
    <span class="k">def</span> <span class="nf">_configure_output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the output size.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">total_output_fields</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">[</span><span class="n">col</span><span class="p">])</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_categories</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_output_embedding</span><span class="p">:</span>
            <span class="c1"># Use a pretrained model for the output embeddings</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_embedding_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_categories</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Using output embeddings. &quot;</span>
                <span class="s2">&quot;Using pretrained model &quot;</span>
                <span class="s2">&quot;of </span><span class="si">%s</span><span class="s2"> embedded dimensions.&quot;</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_output_size</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If no embeddings are used, the output size is the number of categories</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">total_output_fields</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork._initialize_weights">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork._initialize_weights">[docs]</a>
    <span class="k">def</span> <span class="nf">_initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the weights and biases of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;leaky_relu&#39;</span><span class="p">)</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">):</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">ones_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork.forward">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass of the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs *list): The input data.</span>

<span class="sd">        Returns:</span>
<span class="sd">            logits (torch.Tensor): The logits of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_input_embedding</span><span class="p">:</span>
            <span class="n">pre_processed_inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_batch_to_embedding</span><span class="p">(</span>
                <span class="n">batch</span><span class="o">=</span><span class="n">inputs</span>
                <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># Failed approach to use RNN layer</span>
            <span class="c1"># pre_processed_inputs, _ = self.rnn(pre_processed_inputs)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># No embeddings</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">pre_processed_inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_batch_to_one_hot</span><span class="p">(</span>
                    <span class="n">batch</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                    <span class="n">fields_type</span><span class="o">=</span><span class="s2">&quot;inputs&quot;</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
                <span class="n">printer</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                    <span class="s2">&quot;The input fields are not correctly defined.&quot;</span>
                    <span class="s2">&quot; Please make sure that you set the initial dataset&quot;</span>
                    <span class="s2">&quot; To keep identifiers for the input fields.</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot; This is the &#39;store_input_features&#39; of the dataset class &quot;</span>
                    <span class="s2">&quot; method &#39;define_input_output&#39;. (Should be set to True)&quot;</span>
                    <span class="p">)</span>
                <span class="k">raise</span>
        <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span><span class="p">(</span><span class="n">pre_processed_inputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork._process_batch_to_embedding">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork._process_batch_to_embedding">[docs]</a>
    <span class="k">def</span> <span class="nf">_process_batch_to_embedding</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Preprocesses the batch of elements to embeddings.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch (list): The list of elements to preprocess.</span>

<span class="sd">        Returns:</span>
<span class="sd">            embeddings (torch.Tensor): The embeddings of the elements.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get the length of the lists in the input dictionary</span>
        <span class="n">lengths</span><span class="p">:</span> <span class="nb">set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Not all input fields have the same length in this batch&quot;</span>
        <span class="k">except</span> <span class="ne">AssertionError</span><span class="p">:</span>
            <span class="n">printer</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
            <span class="k">raise</span>

        <span class="c1"># Initialize an empty list to hold the embeddings</span>
        <span class="n">embeddings</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># With the following code use the embeddings</span>
        <span class="k">for</span> <span class="n">batch_element</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">):</span>
            <span class="c1"># For each index, get the text from each list in the input dictionary</span>
            <span class="n">embedded_element</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_embedding_model</span><span class="o">.</span><span class="n">get_embedding</span><span class="p">(</span>
                <span class="n">batch_element</span><span class="p">,</span>
                <span class="n">pooling_strategy</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span>
                <span class="p">)</span>
            <span class="n">embeddings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">embedded_element</span><span class="p">)</span>
        <span class="c1"># Stack the embeddings into a tensor. Represents the whole batch</span>
        <span class="n">stacked_embeddings</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">stacked_embeddings</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork._process_batch_to_one_hot">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork._process_batch_to_one_hot">[docs]</a>
    <span class="k">def</span> <span class="nf">_process_batch_to_one_hot</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>
            <span class="n">fields_type</span><span class="p">:</span> <span class="nb">str</span>
            <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Preprocesses the batch of elements (either input or output) to one-hot vectors.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch (list): The list of elements to preprocess.</span>
<span class="sd">            fields_type (str): The fields to preprocess. (inputs or outputs)</span>

<span class="sd">        Returns:</span>
<span class="sd">            one_hot_vectors (torch.Tensor): The one-hot encoded vectors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get the lengths of the lists in the input dictionary</span>
        <span class="n">lengths</span><span class="p">:</span> <span class="nb">set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
        <span class="c1"># Check if all input fields have the same length in this batch</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Not all input fields have the same length in this batch&quot;</span>
        <span class="c1"># Initialize an empty list to hold the one-hot vectors for the whole batch</span>
        <span class="n">all_one_hot_vectors</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Iterate over each batch element getting all the fields for each category</span>
        <span class="k">if</span> <span class="n">fields_type</span> <span class="o">==</span> <span class="s2">&quot;inputs&quot;</span><span class="p">:</span>
            <span class="n">fields</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_categories</span>
        <span class="k">elif</span> <span class="n">fields_type</span> <span class="o">==</span> <span class="s2">&quot;outputs&quot;</span><span class="p">:</span>
            <span class="n">fields</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_categories</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;fields_type must be either &#39;inputs&#39; or &#39;outputs&#39;.&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch_element</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">):</span>
            <span class="c1"># Initialize an empty list to hold the one-hot vectors for each batch element</span>
            <span class="n">one_hot_vectors</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># Iterate over each input category and its corresponding  field</span>
            <span class="k">for</span> <span class="n">category_id</span><span class="p">,</span> <span class="n">field_value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_element</span><span class="p">):</span>
                <span class="c1"># Get the input category and its corresponding input field index</span>
                <span class="n">category</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">fields</span><span class="p">[</span><span class="n">category_id</span><span class="p">]</span>
                <span class="c1"># Convert the input field index to a one-hot vector</span>
                <span class="c1"># Check if the field value is a string representation of list</span>
                <span class="k">if</span> <span class="n">field_value</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;[&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">field_value</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;]&quot;</span><span class="p">):</span>
                    <span class="c1"># field_value is a string representation of a list</span>
                    <span class="n">one_hot</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_multi_one_hot</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">field_value</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># simple string. Just get the index from mapping</span>
                    <span class="c1"># and put it in a tensor</span>
                    <span class="n">field_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">[</span><span class="n">category</span><span class="p">][</span><span class="n">field_value</span><span class="p">])</span>
                    <span class="n">one_hot</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
                        <span class="n">field_ids</span><span class="p">,</span>
                        <span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">[</span><span class="n">category</span><span class="p">])</span>
                        <span class="p">)</span>
                <span class="c1"># Append the one-hot vector to the list</span>
                <span class="n">one_hot_vectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">one_hot</span><span class="p">)</span>
            <span class="c1"># Concatenate the one-hot vectors into a single tensor</span>
            <span class="n">batch_element_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">one_hot_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="c1"># Append the tensor to the list of processed inputs</span>
            <span class="n">all_one_hot_vectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_element_tensor</span><span class="p">)</span>
        <span class="c1"># Stack the processed inputs into a tensor</span>
        <span class="n">processed</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">all_one_hot_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="c1"># Convert the processed inputs to float</span>
        <span class="k">return</span> <span class="n">processed</span><span class="o">.</span><span class="n">float</span><span class="p">()</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork._get_multi_one_hot">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork._get_multi_one_hot">[docs]</a>
    <span class="k">def</span> <span class="nf">_get_multi_one_hot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">category</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">field_value</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Preprocesses the field value to a multi-hot vector.</span>

<span class="sd">        Args:</span>
<span class="sd">            category (str): The category of the field.</span>
<span class="sd">            field_value (str): The field value to preprocess.</span>
<span class="sd">                               This should be a string representation of a list.</span>

<span class="sd">        Returns:</span>
<span class="sd">            one_hot (torch.Tensor): The multi-hot vector.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Convert the field value to a list and get the indexes</span>
        <span class="n">field_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">[</span><span class="n">category</span><span class="p">][</span><span class="n">value</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">(</span><span class="n">field_value</span><span class="p">)]</span>
                <span class="p">)</span>
        <span class="n">one_hot</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
            <span class="n">field_ids</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">[</span><span class="n">category</span><span class="p">])</span>
            <span class="p">)</span>
        <span class="c1"># If there are multiple field indexes, sum them to get the multi-hot vector</span>
        <span class="n">one_hot</span> <span class="o">=</span> <span class="n">one_hot</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># Append the one-hot vector to the list</span>
        <span class="k">return</span> <span class="n">one_hot</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork._get_batch_loss">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork._get_batch_loss">[docs]</a>
    <span class="k">def</span> <span class="nf">_get_batch_loss</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
            <span class="n">batch_logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
            <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
            <span class="n">return_y_one_hot</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the loss for a batch of data.</span>

<span class="sd">        Args:</span>
<span class="sd">            loss_fn (torch.nn.Module): The loss function used to compute the loss.</span>
<span class="sd">            batch_logits (torch.Tensor): The logits from the model.</span>
<span class="sd">            y (torch.Tensor): The target values.</span>
<span class="sd">            return_y_one_hot (bool): Whether to return the processed y or not.</span>
<span class="sd">                                       Useful if needed for testing loop</span>

<span class="sd">        Returns:</span>
<span class="sd">            loss (torch.Tensor): The computed loss.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_output_embedding</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CosineEmbeddingLoss</span><span class="p">),</span> <span class="s2">&quot;Output embeddings require CosineEmbeddingLoss.&quot;</span>
            <span class="c1"># normalize the logits to avoid exploding gradients</span>
            <span class="n">batch_logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span>
                <span class="n">batch_logits</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>
                <span class="p">)</span>
            <span class="c1"># if the output embeddings are NLP embeddings</span>
            <span class="c1"># we need to convert the output strings to embeddings</span>
            <span class="n">y_embeddings</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_batch_to_embedding</span><span class="p">(</span>
                <span class="n">batch</span><span class="o">=</span><span class="n">y</span>
                <span class="p">)</span>
            <span class="c1"># normalize the output embeddings to avoid exploding gradients</span>
            <span class="n">y_embeddings_normalized</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span>
                <span class="n">y_embeddings</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>
                <span class="p">)</span>
            <span class="c1"># in both cases, y_embeddings is a tensor of size (batch_size, embedding_size)</span>
            <span class="c1"># and each row is the embedding of the output category</span>
            <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">loss</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">batch_logits</span><span class="p">,</span> <span class="n">y_embeddings_normalized</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">return_y_one_hot</span><span class="p">:</span>
                <span class="c1"># if y is to be returned as one hot, we have to do it now</span>
                <span class="n">yp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_batch_to_one_hot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">fields_type</span><span class="o">=</span><span class="s2">&quot;outputs&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">yp</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">loss</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">yp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_batch_to_one_hot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">fields_type</span><span class="o">=</span><span class="s2">&quot;outputs&quot;</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">batch_logits</span><span class="p">,</span> <span class="n">yp</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_y_one_hot</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">yp</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork.train_loop">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork.train_loop">[docs]</a>
    <span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">dataloader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains the model using the given dataloader, loss function, and optimizer.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataloader (torch.utils.data.DataLoader): The dataloader containing the training dataset.</span>
<span class="sd">            loss_fn (torch.nn.Module): The loss function used to compute the loss.</span>
<span class="sd">            optimizer (torch.optim.Optimizer): The optimizer used to update the model&#39;s parameters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Save initial weights</span>
        <span class="n">initial_weights</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>

        <span class="c1"># Get the size of the dataloader</span>
        <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
        <span class="c1"># Set the model to training mode - important for batch normalization and dropout layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="c1"># Compute prediction and loss</span>
            <span class="n">batch_logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_batch_loss</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">batch_logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="c1"># Backpropagation - ORDER MATTERS!</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># Check if weights have changed</span>
            <span class="n">weights_changed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
                <span class="p">[(</span><span class="n">initial_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">param</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                 <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
                 <span class="p">]</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">weights_changed</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Warning: Weights did not change for batch </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>

            <span class="c1"># Print the loss every 100 batches</span>
            <span class="k">if</span> <span class="n">batch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">batch</span> <span class="o">==</span> <span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">loss</span><span class="p">,</span> <span class="n">current</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="p">(</span><span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">printer</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">&gt;7f</span><span class="si">}</span><span class="s2">  [</span><span class="si">{</span><span class="n">current</span><span class="si">:</span><span class="s2">&gt;5d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">size</span><span class="si">:</span><span class="s2">&gt;5d</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork.test_loop">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork.test_loop">[docs]</a>
    <span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">dataloader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span>
            <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to evaluate the model on a test dataset.</span>

<span class="sd">        It computes the F1 score, precision, and recall of the model for the test dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataloader (torch.utils.data.DataLoader): The data loader for the test dataset.</span>
<span class="sd">            loss_fn (torch.nn.Module): The loss function used for evaluation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            f1_score (float): The F1 score of the model.</span>
<span class="sd">            precision (float): The precision of the model.</span>
<span class="sd">            recall (float): The recall of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Set the model to evaluation mode - important for batch normalization and dropout layers</span>
        <span class="c1"># Unnecessary in this situation but added for best practices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">num_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
        <span class="c1"># Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode</span>
        <span class="c1"># also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_output_embedding</span><span class="p">:</span>
                <span class="n">correct_positives</span><span class="p">,</span> <span class="n">false_positives</span><span class="p">,</span> <span class="n">total_positives</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
                <span class="n">test_loss</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
                    <span class="c1"># Compute prediction and loss</span>
                    <span class="n">batch_logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                    <span class="n">batch_loss</span><span class="p">,</span> <span class="n">y_one_hot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_batch_loss</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">batch_logits</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">return_y_one_hot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">batch_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="c1"># Calculate the relevance (or priority) of each option</span>
                    <span class="c1"># Has to be done for each batch element separately</span>
                    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">logits</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_logits</span><span class="p">):</span>
                        <span class="c1"># Calculate the probabilities of the model</span>
                        <span class="c1"># We interpret the sigmoid as independent probabilities</span>
                        <span class="n">probabilities</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
                        <span class="c1"># Calculate the estimated correct classification</span>
                        <span class="c1"># Get indices where relevance &gt; 0.5 (default threshold)</span>
                        <span class="n">correct_choices</span><span class="p">,</span> <span class="n">incorrect_choices</span><span class="p">,</span> <span class="n">real_positives</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_get_performance</span><span class="p">(</span>
                                <span class="n">y_one_hot</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                                <span class="n">probabilities</span><span class="p">))</span>
                        <span class="c1"># The count of values correctly reurned as positive</span>
                        <span class="n">correct_positives</span> <span class="o">+=</span> <span class="n">correct_choices</span>
                        <span class="c1"># Count of values that wrongly returned as positive</span>
                        <span class="n">false_positives</span> <span class="o">+=</span> <span class="n">incorrect_choices</span>
                        <span class="c1"># Count of total values that should return as positive</span>
                        <span class="n">total_positives</span> <span class="o">+=</span> <span class="n">real_positives</span>
                <span class="c1"># Compute the precision, recall, and F1 score for the batch</span>
                <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_total_metrics</span><span class="p">(</span>
                    <span class="n">correct_positives</span><span class="p">,</span>
                    <span class="n">false_positives</span><span class="p">,</span>
                    <span class="n">total_positives</span>
                    <span class="p">)</span>
                <span class="c1"># Compute the average loss for the batch</span>
                <span class="n">test_loss</span> <span class="o">/=</span> <span class="n">num_batches</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Output embeddings - needed to identify relevant category by</span>
                <span class="c1"># similarity in the embedded space</span>
                <span class="n">category_embedding_normalized</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_category_embeddings_nlp</span>
                <span class="c1"># Initialize a dictionary to hold the metrics for each threshold</span>
                <span class="n">thresholds_metrics</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="c1"># Iterate over a range of thresholds to find the best one</span>
                <span class="n">test_loss</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="c1"># Iterate over the test dataset</span>
                <span class="n">printer</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Starting test with thresholds&quot;</span><span class="p">)</span>
                <span class="n">threshold_candidates</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">75</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
                    <span class="c1"># Compute prediction and loss</span>
                    <span class="n">batch_logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                    <span class="c1"># Compute the loss for the batch</span>
                    <span class="n">batch_loss</span><span class="p">,</span> <span class="n">y_one_hot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_batch_loss</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">batch_logits</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">return_y_one_hot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="c1"># Accumulate the loss for the batch</span>
                    <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">batch_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="c1"># Calculate the relevance (or priority) of each option</span>
                    <span class="c1"># Has to be done for each batch element separately</span>
                    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">logits</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_logits</span><span class="p">):</span>
                        <span class="c1"># Normalize the logits to focus on the cosine similarity</span>
                        <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="c1"># Calculate the cosine similarity between the logits and the category embeddings</span>
                        <span class="n">cos_sim</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">category_embedding_normalized</span><span class="p">)</span>
                        <span class="c1"># Calculate the probabilities of the model</span>
                        <span class="c1"># We identify the cosine similarities</span>
                        <span class="c1"># between the logits and the category embeddings</span>
                        <span class="c1"># as the probabilities. This is not strictly correct</span>
                        <span class="c1"># but it is a good approximation</span>
                        <span class="n">probabilities</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">cos_sim</span>
                        <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">threshold_candidates</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">thresholds_metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                                <span class="n">thresholds_metrics</span><span class="p">[</span><span class="n">threshold</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                                    <span class="s2">&quot;correct_positives&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                                    <span class="s2">&quot;false_positives&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                                    <span class="s2">&quot;total_positives&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                                    <span class="s2">&quot;test_loss&quot;</span><span class="p">:</span> <span class="mi">0</span>
                                    <span class="p">}</span>
                            <span class="c1"># Initialize the metrics for the threshold</span>
                            <span class="n">correct_choices</span><span class="p">,</span> <span class="n">incorrect_choices</span><span class="p">,</span> <span class="n">real_positives</span> <span class="o">=</span> <span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_get_performance</span><span class="p">(</span>
                                    <span class="n">y_one_hot</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                                    <span class="n">probabilities</span><span class="p">,</span>
                                    <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">)</span>
                                    <span class="p">)</span>
                            <span class="c1"># Accumulate the metrics for the batch</span>
                            <span class="n">thresholds_metrics</span><span class="p">[</span><span class="n">threshold</span><span class="p">][</span><span class="s2">&quot;correct_positives&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">correct_choices</span>
                            <span class="n">thresholds_metrics</span><span class="p">[</span><span class="n">threshold</span><span class="p">][</span><span class="s2">&quot;false_positives&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">incorrect_choices</span>
                            <span class="n">thresholds_metrics</span><span class="p">[</span><span class="n">threshold</span><span class="p">][</span><span class="s2">&quot;total_positives&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">real_positives</span>

                <span class="c1"># Compute the precision, recall, and F1 score for the whole test</span>
                <span class="n">printer</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;starting threshold assessment&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">threshold_candidates</span><span class="p">:</span>
                    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1_score</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_compute_total_metrics</span><span class="p">(</span>
                            <span class="n">thresholds_metrics</span><span class="p">[</span><span class="n">threshold</span><span class="p">][</span><span class="s2">&quot;correct_positives&quot;</span><span class="p">],</span>
                            <span class="n">thresholds_metrics</span><span class="p">[</span><span class="n">threshold</span><span class="p">][</span><span class="s2">&quot;false_positives&quot;</span><span class="p">],</span>
                            <span class="n">thresholds_metrics</span><span class="p">[</span><span class="n">threshold</span><span class="p">][</span><span class="s2">&quot;total_positives&quot;</span><span class="p">]</span>
                            <span class="p">)</span>
                    <span class="p">)</span>
                    <span class="c1"># Store the total metrics for the threshold</span>
                    <span class="n">thresholds_metrics</span><span class="p">[</span><span class="n">threshold</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="s2">&quot;precision&quot;</span><span class="p">:</span> <span class="n">precision</span><span class="p">,</span>
                            <span class="s2">&quot;recall&quot;</span><span class="p">:</span> <span class="n">recall</span><span class="p">,</span>
                            <span class="s2">&quot;f1&quot;</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">,</span>
                            <span class="s2">&quot;test_loss&quot;</span><span class="p">:</span> <span class="n">test_loss</span><span class="o">/</span><span class="n">num_batches</span>
                        <span class="p">})</span>
                    <span class="c1">#</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_similarity_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
                    <span class="n">thresholds_metrics</span><span class="p">,</span>
                    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">thresholds_metrics</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="s2">&quot;f1&quot;</span><span class="p">]</span>
                    <span class="p">)</span>
                <span class="c1"># update it in the config</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_config</span><span class="p">[</span><span class="s2">&quot;similarity_threshold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_similarity_threshold</span>
                <span class="n">printer</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Best threshold: </span><span class="si">%.2f</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_similarity_threshold</span><span class="p">)</span>
                <span class="c1"># Get the metrics for the best threshold into an easy-to-access variable</span>
                <span class="n">best_metrics</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="n">thresholds_metrics</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_similarity_threshold</span><span class="p">]</span>
                <span class="c1"># Get the metrics for the best threshold to printout</span>
                <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">,</span> <span class="n">correct_positives</span><span class="p">,</span> <span class="n">false_positives</span><span class="p">,</span> <span class="n">total_positives</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">best_metrics</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">],</span>
                    <span class="n">best_metrics</span><span class="p">[</span><span class="s2">&quot;recall&quot;</span><span class="p">],</span>
                    <span class="n">best_metrics</span><span class="p">[</span><span class="s2">&quot;f1&quot;</span><span class="p">],</span>
                    <span class="n">best_metrics</span><span class="p">[</span><span class="s2">&quot;test_loss&quot;</span><span class="p">],</span>
                    <span class="n">best_metrics</span><span class="p">[</span><span class="s2">&quot;correct_positives&quot;</span><span class="p">],</span>
                    <span class="n">best_metrics</span><span class="p">[</span><span class="s2">&quot;false_positives&quot;</span><span class="p">],</span>
                    <span class="n">best_metrics</span><span class="p">[</span><span class="s2">&quot;total_positives&quot;</span><span class="p">]</span>
                    <span class="p">)</span>
        <span class="c1"># Print the results</span>
        <span class="n">message_printout</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Test Result: Avg loss: </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="s2">&gt;8.4f</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">F1 Score: </span><span class="si">{</span><span class="n">f1_score</span><span class="si">:</span><span class="s2">&gt;12.8f</span><span class="si">}</span><span class="s2">, </span><span class="se">\n</span><span class="s2">Precision: </span><span class="si">{</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;6.4f</span><span class="si">}</span><span class="s2">, Recall: </span><span class="si">{</span><span class="p">(</span><span class="n">recall</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;6.4f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Correct: </span><span class="si">{</span><span class="n">correct_positives</span><span class="si">:</span><span class="s2">&gt;d</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="n">total_positives</span><span class="si">}</span><span class="s2">, False Positives: </span><span class="si">{</span><span class="n">false_positives</span><span class="si">:</span><span class="s2">&gt;d</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_similarity_threshold</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">message_printout</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best threshold for similarity with embedded outputs: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_similarity_threshold</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="o">+</span> <span class="n">message_printout</span>
            <span class="p">)</span>
        <span class="n">printer</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">message_printout</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_similarity_threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">printer</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Best threshold is chosen by trying and see which one gives the best F1 score.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork._compute_total_metrics">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork._compute_total_metrics">[docs]</a>
    <span class="k">def</span> <span class="nf">_compute_total_metrics</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">correct_positives</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">false_positives</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">total_positives</span><span class="p">:</span> <span class="nb">int</span>
            <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the precision, recall, and F1 score from the performance values.</span>

<span class="sd">        Args:</span>
<span class="sd">            correct_positives (int): The number of correct positives.</span>
<span class="sd">            false_positives (int): The number of false positives.</span>
<span class="sd">            total_positives (int): The total number of real positives.</span>

<span class="sd">        Returns:</span>
<span class="sd">            precision (float): The precision of the model.</span>
<span class="sd">            recall (float): The recall of the model.</span>
<span class="sd">            f1_score (float): The F1 score of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">correct_positives</span> <span class="o">/</span> <span class="p">(</span><span class="n">correct_positives</span> <span class="o">+</span> <span class="n">false_positives</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
            <span class="n">precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">recall</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">correct_positives</span> <span class="o">/</span> <span class="n">total_positives</span>
        <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
            <span class="n">recall</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># compute F1 score</span>
            <span class="n">f1_score</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
            <span class="n">f1_score</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1_score</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork._get_performance">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork._get_performance">[docs]</a>
    <span class="k">def</span> <span class="nf">_get_performance</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">y_one_hot</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
            <span class="n">probabilities</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
            <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span>
            <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the metrics for an individual input in the batch of data.</span>

<span class="sd">        Args:</span>
<span class="sd">            y_one_hot (torch.Tensor): The one-hot encoded target values.</span>
<span class="sd">            probabilities (torch.Tensor): The probabilities of the model.</span>
<span class="sd">            threshold (float): The threshold for the probabilities.</span>

<span class="sd">        Returns:</span>
<span class="sd">            correct_choices (int): The number of correct positive choices.</span>
<span class="sd">            incorrect_choices (int): The number of incorrect positive choices.</span>
<span class="sd">            total_positives (int): The total number of real positives.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">prb_indices</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">(</span><span class="n">probabilities</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="c1"># Get indices where y != 0. This is the correct classification</span>
        <span class="n">y_indices</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_one_hot</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="c1"># Check if the indices are integers</span>
        <span class="c1"># If so, convert them to 1-element lists</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prb_indices</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">prb_indices</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[</span><span class="n">prb_indices</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_indices</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">y_indices</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_indices</span><span class="p">]</span>
        <span class="c1"># Convert indices to sets for comparison</span>
        <span class="n">prb_set</span><span class="p">:</span> <span class="nb">set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">prb_indices</span><span class="p">)</span>
        <span class="n">y_set</span><span class="p">:</span> <span class="nb">set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">y_indices</span><span class="p">)</span>
        <span class="c1"># Find the intersection of the sets</span>
        <span class="n">correct_choices</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prb_set</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">y_set</span><span class="p">))</span>
        <span class="n">incorrect_choices</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prb_set</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">y_set</span><span class="p">))</span>
        <span class="n">total_positives</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">correct_choices</span><span class="p">,</span> <span class="n">incorrect_choices</span><span class="p">,</span> <span class="n">total_positives</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork.evaluate">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork.evaluate">[docs]</a>
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">inp</span><span class="p">,</span>
            <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;monolabel&quot;</span><span class="p">,</span>
            <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluates the model on a single input.</span>

<span class="sd">        This is a low-level function that can be used to evaluate the model</span>
<span class="sd">        on a single input. For a higher-level function that can be used</span>
<span class="sd">        to evaluate the model on a batch of inputs, use the execute function.</span>

<span class="sd">        Args:</span>
<span class="sd">            input (list): The input data.</span>
<span class="sd">                          It is a list, each element of which is a list of strings.</span>
<span class="sd">                          each element of the list corresponds to a different input category.</span>
<span class="sd">                          each element of the inner list corresponds to a different batch element.</span>

<span class="sd">            mode (str): The mode of evaluation.</span>
<span class="sd">                        Can be either &#39;monolabel&#39; or &#39;multilabel&#39; or &#39;priority&#39;.</span>
<span class="sd">        Returns:</span>
<span class="sd">            chosen_categories (list): The chosen categories.</span>
<span class="sd">                                      if mode is &#39;monolabel&#39;, single element list.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="s2">&quot;monolabel&quot;</span><span class="p">,</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">,</span> <span class="s2">&quot;priority&quot;</span>
            <span class="p">],</span> \
            <span class="s2">&quot;Mode must be either &#39;monolabel&#39; or &#39;multilabel&#39; or &#39;priority&#39;.&quot;</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
        <span class="n">output_possibilites</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">i</span><span class="p">:</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">[</span>
                <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_categories</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="p">}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_output_embedding</span><span class="p">:</span>
            <span class="c1"># if using output embedding we need to run the cosine similarity\</span>
            <span class="c1"># with each of the possible outputs</span>
            <span class="c1"># NLP embeddings - needed to identify relevant category by</span>
            <span class="c1"># similarity in the embedded space</span>
            <span class="n">category_embedding_normalized</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_category_embeddings_nlp</span>
            <span class="c1"># Normalize the logits to focus on the cosine similarity</span>
            <span class="c1"># because here logits have shape [1, n] where 1 is the batch size here</span>
            <span class="c1"># we need to normalize the logits along the 1st dimension (rows)</span>
            <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Calculate the cosine similarity between the logits and the category embeddings</span>
            <span class="n">cos_sim</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">category_embedding_normalized</span><span class="p">)</span>
            <span class="c1"># Calculate the probabilities of the model</span>
            <span class="c1"># We identify the cosine similarities</span>
            <span class="c1"># between the logits and the category embeddings</span>
            <span class="c1"># as the probabilities. This is not strictly correct</span>
            <span class="c1"># but it is a good approximation</span>
            <span class="n">probabilities</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">cos_sim</span>
            <span class="c1"># functional.cosinesimilarity automatically squeezes the tensor</span>
            <span class="c1"># if it is a 1D tensor. We need to unsqueeze it to make it a 2D tensor</span>
            <span class="c1"># to be consistent with the code below.</span>
            <span class="k">if</span> <span class="n">probabilities</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">probabilities</span> <span class="o">=</span> <span class="n">probabilities</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_similarity_threshold</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># if not using output embedding we need to process the one_hot vectors</span>
            <span class="c1"># and return the categories associated with the one hot vectors</span>
            <span class="c1"># Get the indices of the highest probabilities by filter with</span>
            <span class="c1"># a threshold of 0.5</span>
            <span class="n">probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.5</span>

        <span class="k">for</span> <span class="n">category_outcome</span> <span class="ow">in</span> <span class="n">probabilities</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;monolabel&quot;</span><span class="p">:</span>
                <span class="n">prb_indices</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">(</span><span class="n">category_outcome</span> <span class="o">==</span> <span class="n">category_outcome</span><span class="o">.</span><span class="n">max</span><span class="p">())</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prb_indices</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="s2">&quot;using monolabel mode but multiple categories are chosen&quot;</span>
                <span class="c1"># Get the category name</span>
                <span class="n">chosen</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[</span><span class="n">output_possibilites</span><span class="p">[</span><span class="n">prb_indices</span><span class="p">]]</span>
            <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">:</span>
                <span class="n">prb_indices</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">(</span><span class="n">category_outcome</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prb_indices</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                    <span class="n">prb_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">prb_indices</span><span class="p">]</span>
                <span class="c1"># Get the categor y names</span>
                <span class="n">chosen</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[</span><span class="n">output_possibilites</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">prb_indices</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># priority mode</span>
                <span class="c1"># create a list of tuples with the category and the probability</span>
                <span class="c1"># sort the list by probability and return the categories</span>
                <span class="n">prb_indices</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
                    <span class="p">[(</span><span class="n">idx</span><span class="p">,</span> <span class="n">category_outcome</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">category_outcome</span><span class="p">))],</span>
                    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span>
                    <span class="p">)</span>
                <span class="n">chosen</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[</span><span class="n">output_possibilites</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">prb_indices</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">chosen</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork.execute">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork.execute">[docs]</a>
    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="nb">list</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;monolabel&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies the model on a batch of data.</span>

<span class="sd">        This is a high-level function that can be used to execute the model</span>
<span class="sd">        on a single input of data. It is just a wrapper around the evaluate function,</span>
<span class="sd">        to make it easier are more intuitive to use.</span>

<span class="sd">        Args:</span>
<span class="sd">            data (list|str): The data to execute the model on.</span>
<span class="sd">                         For a single input category, it can be:</span>
<span class="sd">                           A string</span>
<span class="sd">                           A list of strings.</span>
<span class="sd">                         For multiple input categories, it should be a list of lists</span>
<span class="sd">                          Each element of the outer list corresponds to a different input category.</span>
<span class="sd">                          Each element of the inner list corresponds to a value for that category.</span>
<span class="sd">            mode (str): The mode of evaluation.</span>
<span class="sd">                        Can be either &#39;monolabel&#39; or &#39;multilabel&#39; or &#39;priority&#39;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            chosen_categories (list): The chosen categories.</span>
<span class="sd">                                      if mode is &#39;monolabel&#39;, single element list.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_categories</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_raise_value_error_for_multiple_input_categories</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">single_element_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">]</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">([</span><span class="n">single_element_batch</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">data</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_categories</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_raise_value_error_for_multiple_input_categories</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
                    <span class="k">return</span> <span class="n">outputs</span>
            <span class="k">elif</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">data</span><span class="p">):</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_categories</span><span class="p">),</span> \
                                     <span class="s2">&quot;The number of input categories does not match the input data.&quot;</span>
                <span class="n">printer</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Make sure that the order of the input categories is correct: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_order</span><span class="p">)</span>
                <span class="c1"># make a list of lists of eacn n-th element of each list in data</span>
                <span class="n">batch_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># all lists should have the same length</span>
                <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">element</span><span class="p">)</span> <span class="o">==</span> <span class="n">batch_length</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">data</span><span class="p">),</span> \
                    <span class="s2">&quot;The number of elements in each input category does not match.&quot;</span>
                <span class="c1"># if the input data is correctly formatted</span>
                <span class="c1"># we can evaluate it one by one</span>
                <span class="c1"># and return the results</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="c1"># if the batch length is 1 we can return the result directly</span>
                <span class="k">if</span> <span class="n">batch_length</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>
                <span class="c1"># if the batch length is greater than 1</span>
                <span class="c1"># we have to evaluate each element separately</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_length</span><span class="p">):</span>
                        <span class="n">single_element_batch</span> <span class="o">=</span> <span class="p">[[</span><span class="n">element</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
                        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">single_element_batch</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">))</span>
                    <span class="k">return</span> <span class="n">outputs</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The input data is not correctly formatted.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">single_element_batch</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">_raise_value_error_for_multiple_input_categories</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Formats and logs an error message if the input data does</span>
<span class="sd">        not match the expected format or number of categories.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">error_message</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">error_message</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;Multiple input categories are expected.&quot;</span><span class="p">)</span>
        <span class="n">error_message</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;Please provide the input data as a list of lists.&quot;</span><span class="p">)</span>
        <span class="n">error_message</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;Each element of the outer list should correspond to a different input category.&quot;</span><span class="p">)</span>
        <span class="n">error_message</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The order of categories MUST be as follows: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_order</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">printer</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">error_message</span><span class="p">))</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The device used for training the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            device (torch.device): The device used for training the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output_category_embeddings_nlp</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The output category embeddings for the model.</span>
<span class="sd">        Consider it as base against which to compare the embedded logits.</span>
<span class="sd">        Consider it as a property to avoid accidental changes.</span>

<span class="sd">        Returns:</span>
<span class="sd">            output_category_embeddings_nlp (torch.Tensor): The output category embeddings.</span>

<span class="sd">        Raises:</span>
<span class="sd">            AttributeError: If the embeddings have not been initialized.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nlp_embedding_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Embeddings have not been initialized.&quot;</span><span class="p">)</span>
        <span class="c1"># Make a list of all the output texts which we have to embed</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_nlp_embedding</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_category_embeddings_nlp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># if we are not training the embeddings and they are already computed</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_category_embeddings_nlp</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># if we are training the embeddings or they are not computed</span>
            <span class="c1"># we have to compute them also if it is the first time</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_nlp_embedding</span><span class="p">:</span>
                <span class="n">printer</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="s2">&quot;Embeddings are not computed yet. Computing them now.&quot;</span>
                    <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">This should only happen once.&quot;</span>
                <span class="p">)</span>
            <span class="n">all_outputs_texts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">[</span><span class="n">field</span> <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">[</span><span class="n">category</span><span class="p">]]</span>
                <span class="k">for</span> <span class="n">category</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_categories</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_category_embeddings_nlp</span> <span class="o">=</span> <span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_process_batch_to_embedding</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">all_outputs_texts</span><span class="p">),</span>
                <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_category_embeddings_nlp</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_categories</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The input categories for the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            input_categories (dict): The input categories for the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">[</span><span class="s2">&quot;input_categories&quot;</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_order</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The order of the input categories for the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            input_order (list): The order of the input categories for the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span>
            <span class="n">v</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_categories</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span>
                <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output_categories</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The output categories for the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            output_categories (dict): The output categories for the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">[</span><span class="s2">&quot;output_categories&quot;</span><span class="p">]</span>

<div class="viewcode-block" id="CategoricNeuralNetwork.assess_device">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork.assess_device">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">assess_device</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Determines the device to be used for computation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            device (str): The device to be used for computation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;cuda&quot;</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
            <span class="k">else</span> <span class="s2">&quot;mps&quot;</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
            <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using </span><span class="si">%s</span><span class="s2"> device&quot;</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">device</span></div>


<div class="viewcode-block" id="CategoricNeuralNetwork.add_output_possibility">
<a class="viewcode-back" href="../learning_model.html#learning_model.CategoricNeuralNetwork.add_output_possibility">[docs]</a>
    <span class="k">def</span> <span class="nf">add_output_possibility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">category</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">possibility</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds an output possibility to the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            category (str): The category to add the possibility to.</span>
<span class="sd">            possibility (str): The possibility to add to the category.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">category</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_categories</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Category </span><span class="si">{</span><span class="n">category</span><span class="si">}</span><span class="s2"> is not in the output categories.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_output_embedding</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                <span class="s2">&quot;Cannot add output possibilities when not using output embeddings.&quot;</span>
                <span class="s2">&quot;This would require changing the output size of the model.&quot;</span>
                <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot add output possibilities when not using output embeddings.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">[</span><span class="n">category</span><span class="p">][</span><span class="n">possibility</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">category_mappings</span><span class="p">[</span><span class="n">category</span><span class="p">])</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Added possibility </span><span class="si">%s</span><span class="s2"> to category </span><span class="si">%s</span><span class="s2"> as a new possible output&quot;</span><span class="p">,</span> <span class="n">possibility</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span>
        <span class="c1"># eliminate the output embeddings to recalculate them when needed</span>
        <span class="c1"># This can be done more efficiently (i.e. just appending the new, but for now this is experimental)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_category_embeddings_nlp</span> <span class="o">=</span> <span class="kc">None</span></div>
</div>



<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="c1"># Do nothing</span>
    <span class="c1"># This is just a package for definitions</span>
    <span class="k">pass</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Enric Basso.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>